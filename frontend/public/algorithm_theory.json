{
  "fcfs": {
    "name": "First Come First Serve (FCFS)",
    "summary": "ğŸ§  <strong>First Come First Serve (FCFS)</strong> is the simplest type of CPU scheduling algorithm. As the name suggests, the process that arrives first is executed first, without any preemption. FCFS is a <strong>non-preemptive scheduling</strong> algorithm, meaning once a process starts execution, it cannot be stopped until it completes.\n\nğŸ“‹ In this algorithm, the ready queue operates in a <strong>First-In-First-Out (FIFO)</strong> manner. The processes are executed in the exact order of their arrival, regardless of their burst time. This makes the implementation easy and intuitive but also comes with certain disadvantages.\n\nâ±ï¸ A major drawback of FCFS is the <strong>\"convoy effect\"</strong>, where shorter processes may have to wait for longer ones to finish, leading to <strong>poor average waiting time</strong> and <strong>low CPU utilization</strong>. It's not suitable for time-sharing systems where responsiveness is important.\n\nâœ… However, FCFS is fair in terms of order of execution and useful in simple batch systems or cases where simplicity is preferred over efficiency.\n\nğŸ“Œ <strong>Use cases:</strong> Simple batch processing, systems with uniform job sizes, or when predictability is more important than speed."
  },
  "priority": {
    "name": "Priority Scheduling",
    "summary": "ğŸ¯ <strong>Priority Scheduling</strong> assigns a priority level to each process, and the process with the <strong>highest priority</strong> is executed first. Lower numbers often indicate higher priority (though this can vary by system). This scheduling can be <strong>preemptive</strong> or <strong>non-preemptive</strong> depending on whether a higher-priority process can interrupt a currently running one.\n\nğŸ“‘ If two processes have the same priority, FCFS is usually used to break the tie. This makes the algorithm flexible but also introduces the risk of <strong>starvation</strong>, where low-priority processes may wait indefinitely if high-priority ones keep arriving.\n\nğŸ›¡ï¸ <strong>Aging</strong> is a common technique used to prevent starvation by gradually increasing the priority of waiting processes over time.\n\nğŸ“Œ <strong>Use cases:</strong> Real-time systems, where some tasks must be completed within strict time constraints, or in environments where different tasks have different levels of urgency or importance."
  },
  "rr": {
    "name": "Round Robin (RR)",
    "summary": "ğŸ” <strong>Round Robin (RR)</strong> is one of the most widely used CPU scheduling algorithms, especially in <strong>time-sharing</strong> systems. It assigns a <strong>fixed time quantum</strong> to each process in the ready queue and cycles through them in a <strong>circular queue</strong> fashion.\n\nâ²ï¸ If a process doesn't finish within its allocated time slice, it is moved to the back of the queue, and the next process is scheduled. This continues until all processes are complete.\n\nâš–ï¸ Round Robin is <strong>preemptive</strong> and ensures that all processes get a fair share of CPU time. However, the performance depends heavily on the size of the time quantum:\n- Too small: Excessive context switching overhead.\n- Too large: Becomes similar to FCFS.\n\nğŸ“Œ <strong>Use cases:</strong> Time-sharing operating systems, interactive environments, and multi-user systems where fairness is a key requirement."
  },
  "sstf": {
    "name": "Shortest Seek Time First (SSTF)",
    "summary": "ğŸ§² <strong>Shortest Seek Time First (SSTF)</strong> is a disk scheduling algorithm that selects the I/O request closest to the current head position. This minimizes seek time and improves the average response time of disk operations.\n\nğŸ“ The idea is simple: serve the request that requires the <strong>least movement of the disk arm</strong>. SSTF is a <strong>greedy algorithm</strong>, focusing only on the immediate nearest request, not the overall sequence.\n\nâš ï¸ Although it improves performance over FCFS, SSTF can cause <strong>starvation</strong> for requests that are far from the current head, especially if closer requests keep arriving.\n\nğŸ“Œ <strong>Use cases:</strong> General-purpose operating systems where a moderate balance between speed and fairness is needed. Not ideal for real-time or time-critical systems due to the risk of starvation."
  },
  "scan": {
    "name": "SCAN (Elevator Algorithm)",
    "summary": "ğŸ—ï¸ <strong>SCAN</strong>, also known as the <strong>Elevator Algorithm</strong>, moves the disk arm in one direction, servicing all requests until it reaches the end, then reverses direction and continues. This approach is similar to how an elevator worksâ€”servicing requests in one direction before turning around.\n\nğŸ”„ This reduces long seek times for requests at the far ends of the disk and avoids starvation better than SSTF. It provides <strong>more uniform wait times</strong> compared to FCFS or SSTF.\n\nğŸ§­ However, requests just missed by the head may have to wait for an entire scan cycle.\n\nğŸ“Œ <strong>Use cases:</strong> Multi-user systems and general-purpose disk scheduling where fair service and efficiency are both important."
  },
  "c-scan": {
    "name": "C-SCAN (Circular SCAN)",
    "summary": "ğŸ”„ <strong>Circular SCAN (C-SCAN)</strong> improves upon SCAN by treating the disk as a <strong>circular list</strong>. The disk arm moves in one direction, servicing requests, and when it reaches the end, it jumps back to the start without servicing any requests during the return.\n\nğŸ“ˆ This ensures <strong>more uniform wait times</strong> compared to SCAN because all requests are serviced in a consistent direction, eliminating the advantage of being in the head's path during the return phase.\n\nğŸ“Œ <strong>Use cases:</strong> Systems requiring predictable and balanced disk response times, such as server applications or high-performance computing environments."
  },
  "first fit": {
    "name": "First Fit",
    "summary": "ğŸ“¦ <strong>First Fit</strong> is a memory allocation strategy that allocates the <strong>first block of memory</strong> large enough to accommodate the process. It scans the memory blocks from the beginning and assigns the process to the first suitable free block.\n\nâš¡ It is <strong>simple and fast</strong>, making it efficient in systems where speed is prioritized over optimal memory utilization.\n\nğŸš« However, it can lead to <strong>external fragmentation</strong>, where many small unallocated holes are left in memory that may not be usable.\n\nğŸ“Œ <strong>Use cases:</strong> Embedded systems or real-time systems where fast decision-making is required and memory fragmentation is tolerable."
  },
  "best fit": {
    "name": "Best Fit",
    "summary": "ğŸ” <strong>Best Fit</strong> is a memory allocation strategy that searches the entire list of free memory blocks and assigns the process to the <strong>smallest block</strong> that is still large enough.\n\nğŸ“‰ This reduces leftover unused space and tries to minimize fragmentation. However, it requires <strong>more time to search</strong> for the best-fit block compared to First Fit.\n\nğŸ§© Best Fit can lead to <strong>more fragmentation</strong> in the long run because it leaves behind very small unusable holes in memory.\n\nğŸ“Œ <strong>Use cases:</strong> Systems where memory efficiency is more important than speed of allocation, such as servers or heavily multitasking environments."
  },
  "worst fit": {
    "name": "Worst Fit",
    "summary": "ğŸ“š <strong>Worst Fit</strong> allocates the process to the <strong>largest available memory block</strong>, under the assumption that breaking a large block will leave a sizable chunk still usable.\n\nğŸ§  This strategy aims to avoid small fragments but often ends up wasting larger memory blocks and may result in poor memory utilization over time.\n\nğŸ§© Like Best Fit, it requires scanning the full list of memory blocks, which makes it slower in decision-making.\n\nğŸ“Œ <strong>Use cases:</strong> Educational use, theoretical simulations, or scenarios where we want to observe memory behavior with varying allocation strategies."
  },
  "sjf-np": {
    "name": "Shortest Job First (SJF)",
    "summary": "ğŸ“Š <strong>Shortest Job First (SJF)</strong> is a CPU scheduling algorithm that selects the process with the <strong>shortest burst time</strong> (execution time) next. It's based on the idea that executing shorter jobs first will reduce the average waiting time, improving overall system efficiency.\n\nğŸ§® SJF exists in two forms: <strong>Non-Preemptive SJF</strong>, where once a process starts it runs till completion, and <strong>Preemptive SJF</strong> (also known as <strong>Shortest Remaining Time First, SRTF</strong>), where a shorter job arriving later can preempt the currently running process.\n\nğŸ“‰ This algorithm provides the <strong>lowest average waiting time</strong> for a given set of processes, but it has some practical challenges. Since it relies on knowing the burst time of all processes beforehand, it is difficult to implement in real systems unless historical averages are used.\n\nâš ï¸ It also suffers from the <strong>starvation problem</strong>, where longer processes may never get CPU time if shorter jobs keep arriving.\n\nğŸ“Œ <strong>Use cases:</strong> Batch systems where job length is predictable, simulations, or offline optimization tasks where burst times are known."
  },
  "sjf-p": {
    "name": "Shortest Job First (SJF)",
    "summary": "ğŸ“Š <strong>Shortest Job First (SJF)</strong> is a CPU scheduling algorithm that selects the process with the <strong>shortest burst time</strong> (execution time) next. It's based on the idea that executing shorter jobs first will reduce the average waiting time, improving overall system efficiency.\n\nğŸ§® SJF exists in two forms: <strong>Non-Preemptive SJF</strong>, where once a process starts it runs till completion, and <strong>Preemptive SJF</strong> (also known as <strong>Shortest Remaining Time First, SRTF</strong>), where a shorter job arriving later can preempt the currently running process.\n\nğŸ“‰ This algorithm provides the <strong>lowest average waiting time</strong> for a given set of processes, but it has some practical challenges. Since it relies on knowing the burst time of all processes beforehand, it is difficult to implement in real systems unless historical averages are used.\n\nâš ï¸ It also suffers from the <strong>starvation problem</strong>, where longer processes may never get CPU time if shorter jobs keep arriving.\n\nğŸ“Œ <strong>Use cases:</strong> Batch systems where job length is predictable, simulations, or offline optimization tasks where burst times are known."
  },
  "disk_fcfs": {
    "name": "FCFS (Disk Scheduling)",
    "summary": "ğŸ’½ <strong>First Come First Serve (FCFS)</strong> in disk scheduling works just like it does in CPU scheduling â€” servicing requests in the exact order they arrive, without reordering.\n\nğŸš¨ This often results in high seek times if the requests are scattered all over the disk.\n\nğŸ“‰ It has no optimization logic, so the average performance is poor compared to SSTF or SCAN.\n\nğŸ“Œ <strong>Use cases:</strong> Educational purposes, very simple systems, or where fairness is prioritized over performance."
  },
  "look": {
    "name": "LOOK (Disk Scheduling)",
    "summary": "ğŸ” <strong>LOOK</strong> is an improved version of the SCAN disk scheduling algorithm. Instead of going to the end of the disk, the head moves only as far as the last request in the current direction, then reverses.\n\nâ†”ï¸ This reduces unnecessary head movement compared to SCAN.\n\nğŸ“ˆ LOOK improves seek efficiency while still avoiding starvation, unlike SSTF.\n\nğŸ“Œ <strong>Use cases:</strong> General-purpose OSes where consistent disk response times and efficiency are needed."
  }
}
